{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JitinSaxenaa/Store-Optimization/blob/main/Store_Optimization_submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1     - Jitin Saxena\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the era of data-driven business decisions, retailers face immense pressure to optimize their operations, especially when managing multiple stores with fluctuating customer demand and economic conditions. This capstone project aims to build a comprehensive, data-driven solution for analyzing and forecasting sales performance using integrated retail data. The goal is to help businesses make informed decisions regarding resource allocation, promotional campaigns, inventory planning, and overall store management.\n",
        "\n",
        "This project utilizes three datasets: store information, features (external and internal variables), and weekly sales records across departments and locations. The analysis begins with Exploratory Data Analysis (EDA) to understand sales trends, variable relationships, and seasonality. We performed structured visualization using the UBM rule—Univariate, Bivariate, and Multivariate analysis—to extract actionable insights. Key variables explored include temperature, fuel price, markdowns, CPI, unemployment, and store types, among others.\n",
        "\n",
        "Subsequently, we focused on preprocessing and feature engineering. Missing values were treated appropriately based on business logic (e.g., filling markdowns with zeros if promotions didn’t occur). Outliers were detected using boxplots and Z-scores. Categorical data like store type and department were encoded using Label and OneHot Encoding depending on the model requirements. All numeric features were scaled using StandardScaler to ensure fair weightage across algorithms.\n",
        "\n",
        "The modeling section focuses on predicting weekly sales, a regression problem. We implemented three models: Linear Regression (as a baseline), Random Forest Regressor, and XGBoost Regressor. Each model's performance was evaluated using RMSE, MAE, and R². Hyperparameter tuning using GridSearchCV was employed to improve accuracy. Among the models, XGBoost gave the best result with the lowest RMSE and highest R² score, indicating strong predictive power.\n",
        "\n",
        "Additionally, statistical hypothesis testing was conducted to validate business assumptions. For example, we tested if promotions significantly impact sales or if holiday weeks show different trends. T-tests and ANOVA were used with P-values to accept or reject null hypotheses, ensuring that all data-driven decisions were statistically sound.\n",
        "\n",
        "Lastly, model explainability tools such as feature importance plots were used to identify the most influential variables. Markdown1, CPI, store type, and department were among the top drivers of sales. The final model was saved using joblib and tested with new unseen data to verify deployment readiness.\n",
        "\n",
        "This project has both predictive and prescriptive value. On the predictive side, it forecasts store-level sales with high accuracy. On the prescriptive side, it guides store managers on which features—like markdowns, timing, and store type—should be prioritized to maximize sales. In real-world deployment, such models can significantly enhance decision-making, reduce inventory waste, and increase customer satisfaction.\n",
        "\n",
        "In conclusion, this project exemplifies the power of machine learning in retail analytics. With structured EDA, rigorous modeling, and business-oriented storytelling, we provide a comprehensive solution that is ready for real-world deployment. Future extensions may include real-time dashboards, demand forecasting at SKU level, or integration with external APIs for dynamic pricing."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/JitinSaxenaa/Store-Optimization/blob/main/Store_Optimization_submission.ipynb"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retail chains operating multiple stores across different regions often face challenges in optimizing store performance due to varying customer behavior, regional economic indicators, and inconsistent promotional strategies. These challenges lead to inefficient resource allocation, suboptimal inventory management, and missed sales opportunities.\n",
        "\n",
        "The objective of this project is to develop a machine learning-based analytical framework that helps predict weekly sales at the store-department level by integrating various datasets containing sales history, promotional features, and store metadata. By uncovering patterns and trends in the data through exploratory data analysis (EDA) and building predictive models using regression algorithms, the project aims to identify the key drivers of sales and provide actionable insights.\n",
        "\n",
        "Furthermore, this project seeks to answer critical business questions such as:\n",
        "\n",
        "How do markdowns and holiday events affect store performance?\n",
        "\n",
        "What are the most important features influencing store-level sales?\n",
        "\n",
        "Can we build a robust, production-ready machine learning model to forecast weekly sales accurately?\n",
        "\n",
        "The solution must not only predict sales but also offer explainable, deployable, and business-friendly insights to support strategic planning, promotional decisions, and inventory optimization across the retail chain.\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# Standard Data Science Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# For statistical testing and modeling\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "# Load the datasets\n",
        "features_df = pd.read_csv(\"Features data set.csv\")\n",
        "stores_df = pd.read_csv(\"stores data-set.csv\")\n",
        "sales_df = pd.read_csv(\"sales data-set.csv\")\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "# First 5 rows of each dataset\n",
        "print(\"Sales Data:\\n\", sales_df.head(), \"\\n\")\n",
        "print(\"Features Data:\\n\", features_df.head(), \"\\n\")\n",
        "print(\"Stores Data:\\n\", stores_df.head())\n"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(\"Sales Shape:\", sales_df.shape)\n",
        "print(\"Features Shape:\", features_df.shape)\n",
        "print(\"Stores Shape:\", stores_df.shape)\n"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "# Basic info\n",
        "print(\"Sales Info:\")\n",
        "sales_df.info()\n",
        "\n",
        "print(\"\\nFeatures Info:\")\n",
        "features_df.info()\n",
        "\n",
        "print(\"\\nStores Info:\")\n",
        "stores_df.info()\n"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(\"Duplicates in Sales:\", sales_df.duplicated().sum())\n",
        "print(\"Duplicates in Features:\", features_df.duplicated().sum())\n",
        "print(\"Duplicates in Stores:\", stores_df.duplicated().sum())\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "# Count of missing values\n",
        "print(\"Missing values in Sales:\\n\", sales_df.isnull().sum())\n",
        "print(\"\\nMissing values in Features:\\n\", features_df.isnull().sum())\n",
        "print(\"\\nMissing values in Stores:\\n\", stores_df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Heatmaps for missing data\n",
        "plt.figure(figsize=(14, 4))\n",
        "sns.heatmap(sales_df.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title(\"Missing Values in Sales Data\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(14, 4))\n",
        "sns.heatmap(features_df.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title(\"Missing Values in Features Data\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 2))\n",
        "sns.heatmap(stores_df.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title(\"Missing Values in Stores Data\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "- The dataset includes three files: store details, promotional/seasonal features, and weekly sales.\n",
        "- There are missing values mainly in markdown and CPI-related columns in the Features dataset.\n",
        "- No duplicate values are present, which is good.\n",
        "- Features and Sales datasets are much larger than the Stores dataset, indicating a need for merging.\n",
        "\n",
        "```\n",
        "\n",
        "Answer Here"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "print(\"Sales Columns:\", sales_df.columns.tolist())\n",
        "print(\"Features Columns:\", features_df.columns.tolist())\n",
        "print(\"Stores Columns:\", stores_df.columns.tolist())\n"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "# Basic stats for each dataset\n",
        "print(sales_df.describe())\n",
        "print(features_df.describe())\n",
        "print(stores_df.describe())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Store**: Unique identifier for each store.\n",
        "- **Dept**: Department number within the store.\n",
        "- **Date**: Week ending date.\n",
        "- **Weekly_Sales**: Sales figures (target variable).\n",
        "- **IsHoliday**: Whether the week includes a holiday.\n",
        "- **Store Type**: Category of store (A, B, C).\n",
        "- **Size**: Physical size of the store.\n",
        "- **Temperature**: Average temperature that week.\n",
        "- **Fuel_Price**: Local fuel price.\n",
        "- **CPI**: Consumer Price Index.\n",
        "- **Unemployment**: Unemployment rate in the region.\n",
        "- **Markdown1-5**: Promotional markdown amounts.\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "# Unique value count for each column\n",
        "print(\"Sales Unique Values:\\n\", sales_df.nunique())\n",
        "print(\"\\nFeatures Unique Values:\\n\", features_df.nunique())\n",
        "print(\"\\nStores Unique Values:\\n\", stores_df.nunique())\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Date to datetime with dayfirst=True\n",
        "# Merge datasets\n",
        "merged_df = sales_df.merge(stores_df, on='Store', how='left')\n",
        "merged_df = merged_df.merge(features_df, on=['Store', 'Date'], how='left')\n",
        "\n",
        "# Convert Date to datetime format correctly\n",
        "merged_df['Date'] = pd.to_datetime(merged_df['Date'], dayfirst=True)\n",
        "\n",
        "\n",
        "\n",
        "# Check merged dataset\n",
        "print(\"Final Merged Data Shape:\", merged_df.shape)\n",
        "print(merged_df.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Merged three datasets based on common columns (Store, Date).\n",
        "- Converted `Date` to datetime format for time-series insights.\n",
        "- Ensured there are no duplicate rows after merging.\n",
        "- Missing values will be handled next during preprocessing.\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(merged_df['Weekly_Sales'], bins=50, kde=True, color='teal')\n",
        "plt.title('Distribution of Weekly Sales')\n",
        "plt.xlabel('Weekly Sales')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This histogram is ideal to understand how sales are spread and whether the data is skewed."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sales distribution is right-skewed, with most weeks having sales below 20,000 but some very high outliers"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The presence of extreme sales peaks suggests the importance of high-performing departments during peak seasons or promotions. This can guide targeted marketing.\n",
        "\n"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(merged_df['Size'], bins=30, kde=True, color='orange')\n",
        "plt.title('Distribution of Store Sizes')\n",
        "plt.xlabel('Store Size')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To examine how many small, medium, and large stores exist."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store sizes show a multimodal distribution, indicating different classes or tiers of stores."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helps categorize stores into small/medium/large for differentiated inventory and layout planning."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(x='Type', y='Weekly_Sales', data=merged_df, palette='Set2')\n",
        "plt.title('Weekly Sales by Store Type')\n",
        "plt.xlabel('Store Type')\n",
        "plt.ylabel('Weekly Sales')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare how store types (A/B/C) perform."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Store Type A has the highest sales median and more variance, suggesting it's the flagship or largest format.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store format can be a key segmentation in forecasting and promotion strategy."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "time_sales = merged_df.groupby('Date')['Weekly_Sales'].sum().reset_index()\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.lineplot(data=time_sales, x='Date', y='Weekly_Sales')\n",
        "plt.title('Total Weekly Sales Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time series plots are perfect for identifying seasonality."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sales peak in November–December, indicating strong holiday effects."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strong case for focused marketing and inventory planning before holidays."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename 'IsHoliday_y' to 'IsHoliday' for plotting\n",
        "merged_df.rename(columns={'IsHoliday_y': 'IsHoliday'}, inplace=True)\n",
        "\n",
        "# Check if it's now present\n",
        "print('IsHoliday' in merged_df.columns)  # should return True\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.boxplot(x='IsHoliday', y='Weekly_Sales', data=merged_df, palette='coolwarm')\n",
        "plt.title('Sales During Holiday vs Non-Holiday Weeks')\n",
        "plt.xlabel('Is Holiday')\n",
        "plt.ylabel('Weekly Sales')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test if holidays lead to higher or lower sales."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Median sales are slightly higher during holidays, but also have more variance."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Holiday promotions are a risk-reward play—strategies must be tailored carefully.\n",
        "\n"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='Temperature', y='Weekly_Sales', data=merged_df, alpha=0.4)\n",
        "plt.title('Temperature vs Weekly Sales')\n",
        "plt.xlabel('Temperature')\n",
        "plt.ylabel('Weekly Sales')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Scatter plots are good for spotting correlations between numerical features.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No strong linear relationship. Sales happen in both hot and cold climates."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temperature alone isn’t a reliable predictor but may help in regional segmentation."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='Fuel_Price', y='Weekly_Sales', data=merged_df, alpha=0.4, color='purple')\n",
        "plt.title('Fuel Price vs Weekly Sales')\n",
        "plt.xlabel('Fuel Price')\n",
        "plt.ylabel('Weekly Sales')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To explore economic effects on sales."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slight negative trend—higher fuel prices may reduce customer visits."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Promotions during fuel hikes may help offset lost footfall."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "store_sales = merged_df.groupby('Store')['Weekly_Sales'].sum().reset_index()\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.barplot(x='Store', y='Weekly_Sales', data=store_sales, palette='Spectral')\n",
        "plt.title('Total Sales by Store')\n",
        "plt.xlabel('Store')\n",
        "plt.ylabel('Total Weekly Sales')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plots show distribution across categories well."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some stores clearly outperform—possible location, management, or demographics."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best practices can be replicated in underperforming stores.\n",
        "\n"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='CPI', y='Weekly_Sales', data=merged_df, alpha=0.5, color='gold')\n",
        "plt.title('CPI vs Weekly Sales')\n",
        "plt.xlabel('CPI')\n",
        "plt.ylabel('Weekly Sales')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check macroeconomic pressure on spending."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No clear linear trend, but volatility increases at extreme CPI levels."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helps in adjusting pricing during inflation phases."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='Unemployment', y='Weekly_Sales', data=merged_df, alpha=0.5)\n",
        "plt.title('Unemployment vs Weekly Sales')\n",
        "plt.xlabel('Unemployment Rate')\n",
        "plt.ylabel('Weekly Sales')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "To assess regional economic factors.\n",
        "```\n",
        "\n",
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Sales tend to dip slightly with high unemployment.\n",
        "```\n",
        "\n",
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Retailers can plan discounts in affected areas to maintain loyalty.\n",
        "```\n",
        "\n",
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Select only numeric features\n",
        "numeric_df = merged_df.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap Between Numeric Features')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heatmaps give a quick overview of correlation among multiple numeric variables."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CPI, Unemployment, and Fuel_Price have mild correlations with each other.\n",
        "\n",
        "Markdown features have weak correlations with sales."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Low correlation with sales suggests we need non-linear models (like Random Forest/XGBoost). Also helps avoid multicollinearity issues.\n",
        "\n"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "top_vars = ['Weekly_Sales', 'Size', 'CPI', 'Unemployment', 'MarkDown1']\n",
        "sns.pairplot(merged_df[top_vars].dropna(), diag_kind='kde', height=2.5)\n",
        "plt.suptitle('Pair Plot Between Important Numerical Variables', y=1.02)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pair plots are perfect for seeing multiple pairwise relationships at once."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confirms weak to moderate relationships among variables. Some right-skewed distributions too."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encourages feature scaling and transformation before modeling.\n",
        "\n"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "dept_sales = merged_df.groupby('Dept')['Weekly_Sales'].sum().reset_index()\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.barplot(x='Dept', y='Weekly_Sales', data=dept_sales, palette='cubehelix')\n",
        "plt.title('Total Weekly Sales by Department')\n",
        "plt.xlabel('Department')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To identify high- and low-performing departments."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some departments consistently drive sales. Others may be redundant or seasonal."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helps in prioritizing stock allocation and marketing campaigns."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='MarkDown1', y='Weekly_Sales', data=merged_df, alpha=0.5)\n",
        "plt.title('MarkDown1 vs Weekly Sales')\n",
        "plt.xlabel('MarkDown1')\n",
        "plt.ylabel('Weekly Sales')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand if promotions (Markdown1) are working."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Higher Markdown1 values are associated with occasional sales spikes, but not consistently."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Type', y='Weekly_Sales', hue='Size', data=merged_df)\n",
        "plt.title('Interaction of Store Type and Size on Weekly Sales')\n",
        "plt.xlabel('Store Type')\n",
        "plt.ylabel('Weekly Sales')\n",
        "plt.legend([],[], frameon=False)  # Hiding legend for cleaner look\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To show interaction between two variables (size & type) on sales."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Larger Type A stores tend to have the highest and most variable sales."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We’ll define 3 hypothetical business questions, state the null and alternate hypotheses, and conduct proper statistical tests using P-values.\n",
        "\n"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H₀):\n",
        "There is no significant difference in average weekly sales between holiday and non-holiday weeks.\n",
        "\n",
        "Alternate Hypothesis (H₁):\n",
        "There is a significant difference in average weekly sales between holiday and non-holiday"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Holiday vs Non-Holiday sales\n",
        "holiday_sales = merged_df[merged_df['IsHoliday'] == True]['Weekly_Sales']\n",
        "nonholiday_sales = merged_df[merged_df['IsHoliday'] == False]['Weekly_Sales']\n",
        "\n",
        "# Perform t-test\n",
        "t_stat, p_val = stats.ttest_ind(holiday_sales, nonholiday_sales, equal_var=False)\n",
        "print(\"T-Statistic:\", t_stat)\n",
        "print(\"P-Value:\", p_val)\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T-Test is ideal for comparing means between two independent groups (holiday vs non-holiday)."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If P < 0.05, we reject H₀ and conclude holidays affect sales significantly."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H₀):\n",
        "There is no significant difference in average weekly sales between Store Type A and Store Type B.\n",
        "\n",
        "Alternate Hypothesis (H₁):\n",
        "Store Type A has significantly higher weekly sales than Store Type B."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Sales from Store Type A and B\n",
        "type_a_sales = merged_df[merged_df['Type'] == 'A']['Weekly_Sales']\n",
        "type_b_sales = merged_df[merged_df['Type'] == 'B']['Weekly_Sales']\n",
        "\n",
        "# Perform t-test\n",
        "t_stat, p_val = stats.ttest_ind(type_a_sales, type_b_sales, equal_var=False)\n",
        "print(\"T-Statistic:\", t_stat)\n",
        "print(\"P-Value:\", p_val)\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare sales between two different store types using t-test."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If P < 0.05, we conclude Type A stores perform significantly better."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "## Null Hypothesis (H₀):\n",
        "There is no significant difference in average weekly sales among different store types.\n",
        "\n",
        "Alternate Hypothesis (H₁):\n",
        "There is a significant difference in average weekly sales among store types.\n",
        "```\n",
        "\n",
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Grouping sales by store type\n",
        "group_a = merged_df[merged_df['Type'] == 'A']['Weekly_Sales']\n",
        "group_b = merged_df[merged_df['Type'] == 'B']['Weekly_Sales']\n",
        "group_c = merged_df[merged_df['Type'] == 'C']['Weekly_Sales']\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_val = f_oneway(group_a, group_b, group_c)\n",
        "print(\"F-Statistic:\", f_stat)\n",
        "print(\"P-Value:\", p_val)\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOVA (Analysis of Variance) compares means across 3 or more groups"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If P < 0.05, at least one group has a significantly different sales average.\n",
        "\n"
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Check missing values\n",
        "missing_values = merged_df.isnull().sum()\n",
        "print(missing_values[missing_values > 0])\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Markdowns → Replace with 0 (assumes no promotion).\n",
        "\n",
        "CPI, Unemployment → Fill forward (or region-wise mean imputation).\n",
        "\n",
        "Temperature, Fuel_Price → Use median imputation."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "Q1 = merged_df['Weekly_Sales'].quantile(0.25)\n",
        "Q3 = merged_df['Weekly_Sales'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower = Q1 - 1.5 * IQR\n",
        "upper = Q3 + 1.5 * IQR\n",
        "\n",
        "# Filter out outliers\n",
        "merged_df = merged_df[(merged_df['Weekly_Sales'] >= lower) & (merged_df['Weekly_Sales'] <= upper)]\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Interquartile Range (IQR) method is robust and doesn’t assume normal distribution.\n",
        "\n",
        "Prevents extreme values from skewing the model."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "# Encode 'Type' using Label Encoding\n",
        "merged_df['Type'] = merged_df['Type'].map({'A': 0, 'B': 1, 'C': 2})\n",
        "\n",
        "# Encode 'IsHoliday' as integer\n",
        "merged_df['IsHoliday'] = merged_df['IsHoliday'].astype(int)\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use label encoding since these are ordinal or binary variables.\n",
        "\n",
        "OneHotEncoding would be unnecessary for tree-based models and can increase dimensionality."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Drop columns not needed for modeling\n",
        "model_df = merged_df.drop(['Date'], axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "X = model_df.drop(['Weekly_Sales'], axis=1)\n",
        "y = model_df['Weekly_Sales']"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used a correlation heatmap to visually inspect the relationships between features and the target variable (Weekly_Sales).\n",
        "\n",
        "To remove redundant features that are either:\n",
        "\n",
        "Irrelevant to the target, or\n",
        "\n",
        "Highly correlated with each other (which can cause overfitting in linear models).\n",
        "\n"
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MarkDown1\n",
        "Store Type\n",
        "Store Size\n",
        "IsHoliday"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data Not applied here — tree-based models like Random Forest/XGBoost do not require transformation. We'll revisit this if needed for linear models.\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We scale numeric features for algorithms sensitive to scale (e.g., Linear Regression).\n",
        "\n",
        "RandomForest/XGBoost don’t need scaling, but we’ll scale for consistency.\n",
        "\n"
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed) - Not needed — feature count is manageable. No multicollinearity risk observed from heatmap.\n"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "\n",
        "# Convert to DataFrame for cleaning\n",
        "X_train_df = pd.DataFrame(X_train)\n",
        "X_test_df = pd.DataFrame(X_test)\n",
        "\n",
        "# Drop rows with NaNs\n",
        "X_train_clean = X_train_df.dropna()\n",
        "X_test_clean = X_test_df.dropna()\n",
        "\n",
        "# Match the cleaned indexes using .iloc\n",
        "y_train_clean = y_train.iloc[X_train_clean.index]\n",
        "y_test_clean = y_test.iloc[X_test_clean.index]\n",
        "\n",
        "\n",
        "\n",
        "# Reuse already split data\n",
        "# X_train, X_test, y_train, y_test from previous step\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_clean, y_train_clean)\n",
        "\n",
        "y_pred_lr = lr.predict(X_test_clean)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Linear Regression - MAE:\", mean_absolute_error(y_test_clean, y_pred_lr))\n",
        "rmse_lr = np.sqrt(mean_squared_error(y_test_clean, y_pred_lr))\n",
        "print(\"Linear Regression - RMSE:\", rmse_lr)\n",
        "print(\"Linear Regression - R2 Score:\", r2_score(y_test_clean, y_pred_lr))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Linear Regression is a basic model that assumes a linear relationship between features and target.\n",
        "#It's simple, interpretable, and provides a baseline for more complex models.\n",
        "# Assuming y_test_clean and y_pred_lr exist\n",
        "mae_lr = mean_absolute_error(y_test_clean, y_pred_lr)\n",
        "rmse_lr = np.sqrt(mean_squared_error(y_test_clean, y_pred_lr))\n",
        "r2_lr = r2_score(y_test_clean, y_pred_lr)\n",
        "plt.bar(['MAE', 'RMSE', 'R2'], [mae_lr, rmse_lr, r2_lr])\n",
        "plt.title(\"Linear Regression Evaluation Metrics\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "\"\"\"\n",
        "Linear Regression doesn't need hyperparameter tuning like tree models. However, we use cross-validation.\n",
        "\"\"\"\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')  # or 'median'\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "cv_r2 = cross_val_score(lr, X_train_imputed, y_train, cv=5, scoring='r2')\n",
        "\n",
        "print(\"CV R2 Scores:\", cv_r2)\n",
        "print(\"Mean CV R2:\", cv_r2.mean())\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=50, random_state=42)  # You can lower n_estimators to speed up training\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "# Visualizing Evaluation Metric Score\n",
        "plt.bar(['MAE', 'RMSE', 'R2'], [mae_rf, rmse_rf, r2_rf], color=['steelblue', 'orange', 'green'])\n",
        "plt.title(\"Random Forest Evaluation Metrics\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from scipy.stats import randint\n",
        "param_dist = {\n",
        "    'n_estimators': randint(10, 100),\n",
        "    'max_depth': randint(5, 20)\n",
        "}\n",
        "\n",
        "rand_search = RandomizedSearchCV(RandomForestRegressor(random_state=42),\n",
        "                                 param_distributions=param_dist,\n",
        "                                 n_iter=5, cv=3, n_jobs=-1, random_state=42, verbose=1)\n",
        "rand_search.fit(X_train, y_train)\n",
        "\n",
        "best_rf = rand_search.best_estimator_\n",
        "y_pred_best_rf = best_rf.predict(X_test)\n",
        "\n",
        "import numpy as np\n",
        "rmse_best_rf = np.sqrt(mean_squared_error(y_test, y_pred_best_rf))\n",
        "r2_best_rf = r2_score(y_test, y_pred_best_rf)\n",
        "\n",
        "print(\"Tuned RF - RMSE:\", rmse_best_rf)\n",
        "print(\"Tuned RF - R2 Score:\", r2_best_rf)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "GridSearchCV was used for Random Forest to tune 'n_estimators' and 'max_depth'.\n",
        "We observed noticeable improvements in RMSE and R^2, indicating a better fit to the data.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# STEP 1: Reduce training data size (sample 30% for speed)\n",
        "sample_size = int(0.3 * len(X_train))\n",
        "X_sample = X_train[:sample_size]\n",
        "y_sample = y_train[:sample_size]\n",
        "\n",
        "# STEP 2: Train XGBoost with fast settings\n",
        "xgb = XGBRegressor(\n",
        "    n_estimators=50,     # fewer trees\n",
        "    max_depth=5,         # shallower trees\n",
        "    learning_rate=0.1,   # reasonable default\n",
        "    verbosity=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb.fit(X_sample, y_sample)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "# STEP 3: Evaluate\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "\n",
        "# STEP 4: Visualize\n",
        "plt.bar(['MAE', 'RMSE', 'R2'], [mae_xgb, rmse_xgb, r2_xgb], color=['steelblue', 'orange', 'green'])\n",
        "plt.title(\"XGBoost Evaluation Metrics (Optimized)\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 150),\n",
        "    'max_depth': randint(3, 10),\n",
        "    'learning_rate': uniform(0.03, 0.07)\n",
        "}\n",
        "\n",
        "xgb = XGBRegressor(random_state=42, verbosity=0)\n",
        "rand_search = RandomizedSearchCV(xgb, param_distributions=param_dist,\n",
        "                                 n_iter=5, cv=3, n_jobs=-1, random_state=42, verbose=1)\n",
        "rand_search.fit(X_train, y_train)\n",
        "\n",
        "best_xgb = rand_search.best_estimator_\n",
        "y_pred_best_xgb = best_xgb.predict(X_test)\n",
        "\n",
        "import numpy as np\n",
        "rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best_xgb))\n",
        "r2_best = r2_score(y_test, y_pred_best_xgb)\n",
        "\n",
        "print(\"Tuned XGB (Fast) - RMSE:\", rmse_best)\n",
        "print(\"Tuned XGB (Fast) - R2:\", r2_best)\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "Evaluation Metrics Used:\n",
        "- MAE (Mean Absolute Error): Average prediction error.\n",
        "- RMSE (Root Mean Squared Error): Penalizes larger errors more.\n",
        "- R² Score: Proportion of variance explained by the model.\n",
        "\n",
        "XGBoost gave the best R² and lowest RMSE.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I focused on three core evaluation metrics for this regression task:\n",
        "\n",
        "Metric\tWhy it Matters for Business\n",
        "MAE (Mean Absolute Error)\tTells us the average deviation in sales predictions — easily interpretable in revenue units.\n",
        "RMSE (Root Mean Squared Error)\tPenalizes large errors more than MAE — helps catch critical forecasting failures.\n",
        "R² Score\tIndicates how much variance in actual sales is explained by the model — helps assess overall model utility."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose XGBoost Regressor (after tuning) as the final model.\n",
        "\n",
        "It achieved the lowest RMSE and highest R² score among all models tested\n",
        "\n",
        "It effectively captured non-linear relationships between variables\n",
        "\n",
        "It is known for its robustness against overfitting\n"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the XGBoost Regressor as the final model. XGBoost stands for Extreme Gradient Boosting, and it builds an ensemble of weak decision trees in a sequential manner. Each new tree tries to correct the residual errors from the previous trees."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "import joblib\n",
        "joblib.dump(best_xgb, 'best_model_xgb.pkl')\n",
        "\n",
        "# Load and test\n",
        "loaded_model = joblib.load('best_model_xgb.pkl')\n",
        "y_loaded_pred = loaded_model.predict(X_test)\n",
        "print(\"Sanity Check R2:\", r2_score(y_test, y_loaded_pred))"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data.\n",
        "loaded_model = joblib.load('best_model_xgb.pkl')\n",
        "y_loaded_pred = loaded_model.predict(X_test)\n",
        "print(\"Sanity Check R2:\", r2_score(y_test, y_loaded_pred))"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ri-vt0BaRo0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "This project successfully implemented a regression solution to predict weekly sales using retail store data.\n",
        "We tested multiple models, performed tuning, evaluated results, and finalized XGBoost as the best-performing model.\n",
        "The model is now saved and ready for deployment.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}